```{r, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}
library(stringr)
library(reshape2)
library(psych)
library(car)
library(plyr)

load(file="data/HW3.Rdata")
names(results) <- str_replace(names(results), "TScore", "")
results$Latency <- log(results$Latency)
scores <- dcast(results, formula = Subject + EVT + PPVT + Age ~ Condition, 
                mean, value.var = "Latency")
lengths <- dcast(results, formula = Subject + EVT + PPVT + Age ~ Condition, 
                  length, value.var = "Latency")
lengths <- mutate(lengths, Usable = nonsense + real)
just_scores <- subset(scores, select=-Subject)
long_scores <- melt(scores, measure.vars=c("nonsense", "real"), 
                    value.name="Latency", variable.name="Condition")
```


Exercises about Rex Kline's book (for Tue., Sept. 24)
===============================================================================

> A. Read pages 51--72 very carefully. Be prepared to explain to a novice what the topics below mean and why they are particularly important in SEM. For each of the topics you should be able to say two or three sentences without looking at your notes. 

**Positive definiteness of matrices (causes, indicators of nonpositive definiteness)**

In order for us to do the SEM analysis on the covariance matrix (a description of the variables in our data and how they vary together), the matrix needs to be well-formed--that is, positive definite--so that we can do some linear algebra on them. The indicators of nonpositive definiteness:

1. The matrix is nonsingular, or invertible.
2. All eigenvalues of the matrix are greater than zero.
3. The determinant of the matrix is greater than zero.
4. All of the correlations and covariances are not out of bounds.

**Collinearity (between a pair of variables and between a variable and two or more others)**

Collinearity indicates that two separate variables are measuring the same thing. 


**Outliers (univariate outliers, multivariate outliers)**

Outliers are extreme values that distort or exaggerate trends in the data.

**Missing data (ignorable, systematic, MAR, MCAR, available case methods, mean substitution, regression-based imputation, model-based imputation)**

Ignorable missing data is not systematic. If missingness is systematic, the results from the available cases may not generalize to the targeted population. Missing at random means that the missing scores only vary by chance. 

**Normality (univariate, multivariate) and transformations**

**Linearity and homoscedasticity**

**Relative variances**

**Reliability and validity**

> B. Make a table that looks like the trouble shooting guide of the last dishwasher you bought. In the left column are the potential problems, in the middle column are the ways to diagnose the problems, and in the right column are ways to solve the problems (0.5 to 1 page max.). 



> C. Once you are done with A. and B., take a recent data set of yours, select 5 to 10 variables that are important to your hypotheses, and do some data screening. Among the selected variables there should be at most one experimental manipulation with two levels. Selecting only measured variables is fine, too. Go through the table you made in B. Check whether each problem is present in your variables, i.e., check whether your covariance matrix is positive definite, check whether there is a collinearity problem in your data (e.g., by computing the variance inflation factor for each of the variables), check whether there are outliers (e.g., by computing Mahalanobis distance for each observation), and so forth. Summarize your data screening (what you did and what you found) in Â½ to 1 page. If you want you can put additional information (R script, box plots, etc.) in an appendix, but your summary should be informative by itself (I must be able to understand it without looking in the appendix). 

I have chosen to screen some reaction time data from a language processing task with 30--45 month-old children. I am interested in whether vocabulary size predicts reaction time. There are two trial conditions, one in which the child is prompted to look a familiar object named using a real word (e.g., _dog_) and another condition in which the child is prompted to look at unfamiliar object named with a nonsense word. Therefore the five variables in this dataset are are two different measures of vocabulary, age in months, reaction time and trial condition.

These reaction times already underwent one iteration of screening and correction: Blinks and other random missingness in the eye-tracking data were imputed using neighboring data, RTs that were impossible fast (by virtue of how eye-movements work) were excluded and then RTs that were more than 2 SDs above the mean were dropped within each condition. Since reaction times are practically unbounded durations, trimming the slowest 5% of RTs seems appropriate.

Missingness was present in the dataset because not every trial yielded a usable reaction time, and a number of reaction times were trimmed as described above. It is possible that attention to the task predicts the number of usable reaction times, and therefore that the number of usable observations within each subject is not ignorable missing data. I checked against this possibility by regressing the number of reaction times onto condition, two measures of vocabulary, and age. There was a signifcant effect of age such that increasing one-month in age predicted an increase in usable data by 0.76 trials, controlling all other predictors. In other words, older kids may dispropriately represented in the unaggregated data-set.

```{r}
lengths <- melt(lengths, measure.vars=c("nonsense", "real"))
lengths <- mutate(lengths, Condition = ifelse(variable == "nonsense", -.5, .5))
summary(lm(value ~ EVT + PPVT + Age + Condition, lengths))
```

For the purposes of this exercise, I aggregated observations by condition within each subject by computing mean reaction times. (A more robust analysis would use these repeated measures to its advantage, of course.) The aggregated data contains no missing observations.

The covariance matrix showed positive eigenvalues, so it is positive definite.

```{r}
eigen(cov(just_scores))
```

Collinearity was assessed by computing the squared multiple correlations of each variable as well as examining the bivariate correlations. All of these correlations were less than 0.90. The highest correlation was between expressive and receptive vocabulary measures, _r_ = 0.73, which suggests that these scores measure different aspects of the same underlying vocabulary construct. 

```{r}
smc(just_scores)
cor(just_scores)
```

Univariate normality was using measures for skew and kurtosis. Adequate values were found for these measures.

```{r}
scatterplotMatrix(just_scores)
describe(just_scores)
```






> D. Do exercise 5 on page 74 (preferably in R but other software is fine too). Write a one-sentence conclusion. 

> Create a single word document with your troubleshooting table (B.), the summary of your data screening (C.), the normal probability plot plus conclusion (D.), and an appendix (optional) and send me the document on Tuesday, by 11:30 am. _Note: You should do these exercises by yourself but feel free to consult with others and to ask them for help. If you give help to others, help them find the solution themselves rather than giving them the solution._



